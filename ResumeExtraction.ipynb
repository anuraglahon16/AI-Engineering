{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNv+b0l/JNOARD9BgR5sU8p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuraglahon16/AI-Engineering/blob/main/ResumeExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install langchain langchain-core langchain-community langchain_openai huggingface-hub requests -q -U\n",
        "!pip install arxiv pymupdf faiss-cpu chromadb tenacity PyPDF2 -q\n",
        "\n",
        "# Set up environment variables\n",
        "import os\n",
        "import getpass\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.tools import BaseTool\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Get user input for the resume file path\n",
        "resume_file_path = input(\"Enter the path to your resume file: \")\n",
        "\n",
        "# Load the resume file (PDF)\n",
        "reader = PdfReader(resume_file_path)\n",
        "resume_content = \"\"\n",
        "for page in reader.pages:\n",
        "    resume_content += page.extract_text()\n",
        "\n",
        "# Split the resume into chunks\n",
        "text_splitter = CharacterTextSplitter(separator='\\n---\\n', chunk_size=1000, chunk_overlap=0)\n",
        "resume_docs = text_splitter.split_documents([Document(page_content=resume_content)])\n",
        "\n",
        "# Create vector database and store the resume\n",
        "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-ada-002\")\n",
        "db = Chroma.from_documents(resume_docs, embedding_model, persist_directory='./chroma_db')\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=150)\n",
        "\n",
        "# Initialize the conversation memory\n",
        "chat_memory = ConversationBufferMemory(ai_prefix=\"AI Assistant\")\n",
        "\n",
        "# Define the conversation template\n",
        "template = \"\"\"\n",
        "You're an AI assistant and your task is to gather additional details from a candidate after they upload their resume.\n",
        "\n",
        "At the beginning, shortly describe the purpose of this conversation.\n",
        "\n",
        "You should gather answers for the following questions:\n",
        "\n",
        "- What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
        "- Can you provide an example of a project or accomplishment that demonstrates your qualifications?\n",
        "- What are your career goals and how do you see this position aligning with those goals?\n",
        "\n",
        "Don't answer the question you are asking.\n",
        "\n",
        "Be patient and encouraging if the candidate doesn't know how to answer some questions, and help guide them.\n",
        "\n",
        "Ask one question at a time.\n",
        "\n",
        "Once you have gathered all the details, thank the candidate for their responses, summarize the relevant information that will help the recruiter better understand their qualifications, and put ''\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI assistant:\n",
        "\"\"\"\n",
        "\n",
        "# Create the conversation prompt\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "conversation = ConversationChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=chat_memory\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "current_input = \"I have uploaded my resume and I'm ready to provide additional information.\"\n",
        "\n",
        "end_seq = ''\n",
        "candidate_details = ''\n",
        "\n",
        "while True:\n",
        "    ai_response = conversation.predict(input=current_input)\n",
        "    print(ai_response)\n",
        "\n",
        "    if end_seq in ai_response:\n",
        "        candidate_details = chat_memory.chat_memory.messages[-1].content.replace(end_seq, '')\n",
        "        break\n",
        "\n",
        "    user_input = input('Candidate: ')\n",
        "    current_input = user_input\n",
        "\n",
        "# Initialize the RAG tool\n",
        "rag_tool = Tool(\n",
        "    name=\"RAG System\",\n",
        "    func=lambda q: db.similarity_search(q, k=3),\n",
        "    description=\"Useful for retrieving relevant information from the candidate's resume.\"\n",
        ")\n",
        "\n",
        "# Generate the summary using the agent with retry logic\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def generate_summary(query):\n",
        "    agent = initialize_agent([rag_tool], llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "    return agent.run(f\"Use the resume and additional details provided by the candidate to generate a summary for the recruiter: {query}\")\n",
        "\n",
        "try:\n",
        "    summary = generate_summary(candidate_details)\n",
        "except Exception as e:\n",
        "    print(f\"Error generating summary: {str(e)}\")\n",
        "    summary = \"I apologize, I encountered an error while generating the summary. I tried using the available information from the resume and additional details provided by the candidate, but I still don't have enough relevant information to provide a satisfactory summary for the recruiter. I would recommend gathering more specific details from the candidate related to their qualifications and experience.\"\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary for the Recruiter:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZdJZBO0xaCe",
        "outputId": "afa97f4c-bc3c-40f5-9c10-78984b21b702"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hOpenAI API Key:··········\n",
            "Enter the path to your resume file: /content/Anurag Lahon Resume 2024.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great! Thank you for uploading your resume. The purpose of this conversation is to gather additional details to better understand your qualifications for the position you're applying for. \n",
            "\n",
            "What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI need to look for specific skills or experiences on the candidate's resume that are relevant to the position.\n",
            "Action: RAG System\n",
            "Action Input: Candidate's resume\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\")]\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI need to identify specific skills or experiences that are relevant to the position the candidate is applying for.\n",
            "Action: RAG System\n",
            "Action Input: Candidate's resume\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\")]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have identified the specific skills and experiences that are relevant to the position the candidate is applying for.\n",
            "Final Answer: The candidate has skills in Database Management, Data Visualization, Tools like Jupyter and AWS, Programming Languages such as Python and SQL, Big Data Ecosystem, AI/ML Techniques, Generative AI Technologies, and experience in Data Analysis, Data Engineering, Machine Learning, and Teaching Assistant roles.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Summary for the Recruiter:\n",
            "The candidate has skills in Database Management, Data Visualization, Tools like Jupyter and AWS, Programming Languages such as Python and SQL, Big Data Ecosystem, AI/ML Techniques, Generative AI Technologies, and experience in Data Analysis, Data Engineering, Machine Learning, and Teaching Assistant roles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install langchain langchain-core langchain-community langchain_openai huggingface-hub requests -q -U\n",
        "!pip install arxiv pymupdf faiss-cpu chromadb tenacity PyPDF2 -q\n",
        "\n",
        "# Set up environment variables\n",
        "import os\n",
        "import getpass\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.tools import BaseTool\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Get user input for the resume file path\n",
        "resume_file_path = input(\"Enter the path to your resume file: \")\n",
        "\n",
        "# Load the resume file (PDF)\n",
        "reader = PdfReader(resume_file_path)\n",
        "resume_content = \"\"\n",
        "for page in reader.pages:\n",
        "    resume_content += page.extract_text()\n",
        "\n",
        "# Split the resume into chunks\n",
        "text_splitter = CharacterTextSplitter(separator='\\n---\\n', chunk_size=1000, chunk_overlap=0)\n",
        "resume_docs = text_splitter.split_documents([Document(page_content=resume_content)])\n",
        "\n",
        "# Create vector database and store the resume\n",
        "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-ada-002\")\n",
        "db = Chroma.from_documents(resume_docs, embedding_model, persist_directory='./chroma_db')\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=150)\n",
        "\n",
        "# Initialize the conversation memory\n",
        "chat_memory = ConversationBufferMemory(ai_prefix=\"AI Assistant\")\n",
        "\n",
        "# Define the conversation template\n",
        "template = \"\"\"\n",
        "You're an AI assistant and your task is to gather additional details from a candidate after they upload their resume.\n",
        "\n",
        "At the beginning, shortly describe the purpose of this conversation.\n",
        "\n",
        "You should gather answers for the following questions:\n",
        "\n",
        "- What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
        "- Can you provide an example of a project or accomplishment that demonstrates your qualifications?\n",
        "- What are your career goals and how do you see this position aligning with those goals?\n",
        "\n",
        "Don't answer the question you are asking.\n",
        "\n",
        "Be patient and encouraging if the candidate doesn't know how to answer some questions, and help guide them.\n",
        "\n",
        "Ask one question at a time and wait for the candidate's response before asking the next question.\n",
        "\n",
        "Once you have gathered all the details, thank the candidate for their responses, summarize the relevant information that will help the recruiter better understand their qualifications, and put ''\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI assistant:\n",
        "\"\"\"\n",
        "\n",
        "# Create the conversation prompt\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "conversation = ConversationChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=chat_memory\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "print(\"AI Assistant: Great! Thank you for uploading your resume. The purpose of this conversation is to gather additional details to better understand your qualifications for the position you're applying for.\")\n",
        "print(\"AI Assistant: What specific skills or experiences do you have that are relevant to the position you're applying for?\")\n",
        "\n",
        "candidate_details = \"\"\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Candidate: \")\n",
        "    candidate_details += f\"Candidate: {user_input}\\n\"\n",
        "\n",
        "    ai_response = conversation.predict(input=user_input)\n",
        "    print(f\"AI Assistant: {ai_response}\")\n",
        "\n",
        "    if '' in ai_response:\n",
        "        candidate_details += f\"AI Assistant: {ai_response.replace('', '')}\\n\"\n",
        "        break\n",
        "\n",
        "# Initialize the RAG tool\n",
        "rag_tool = Tool(\n",
        "    name=\"RAG System\",\n",
        "    func=lambda q: db.similarity_search(q, k=3),\n",
        "    description=\"Useful for retrieving relevant information from the candidate's resume.\"\n",
        ")\n",
        "\n",
        "# Generate the summary using the agent with retry logic\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def generate_summary(query):\n",
        "    agent = initialize_agent([rag_tool], llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "    return agent.run(f\"Use the resume and additional details provided by the candidate to generate a summary for the recruiter: {query}\")\n",
        "\n",
        "try:\n",
        "    summary = generate_summary(candidate_details)\n",
        "except Exception as e:\n",
        "    print(f\"Error generating summary: {str(e)}\")\n",
        "    summary = \"I apologize, I encountered an error while generating the summary. I tried using the available information from the resume and additional details provided by the candidate, but I still don't have enough relevant information to provide a satisfactory summary for the recruiter. I would recommend gathering more specific details from the candidate related to their qualifications and experience.\"\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary for the Recruiter:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6pkBJEwxuev",
        "outputId": "32682dd2-f8aa-4a3b-9dbf-0b4a9a9a1460"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "OpenAI API Key:··········\n",
            "Enter the path to your resume file: /content/Anurag Lahon Resume 2024.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Assistant: Great! Thank you for uploading your resume. The purpose of this conversation is to gather additional details to better understand your qualifications for the position you're applying for.\n",
            "AI Assistant: What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
            "Candidate: I am skilled in Python, SQL,AWS\n",
            "AI Assistant: Hello, thank you for sharing your skills with me. The purpose of our conversation is to gather additional details from you after you uploaded your resume. Could you please provide more information on the specific skills or experiences you have that are relevant to the position you're applying for?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI need to gather more specific information about the candidate's skills and experiences related to the position they are applying for.\n",
            "Action: RAG System\n",
            "Action Input: Python, SQL, AWS\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\")]\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI have found relevant information about the candidate's skills and experiences related to Python, SQL, and AWS.\n",
            "Action: RAG System\n",
            "Action Input: Python, SQL, AWS\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\")]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have gathered all the relevant information about the candidate's skills and experiences related to Python, SQL, and AWS.\n",
            "Final Answer: The candidate is skilled in Python, SQL, and AWS, with experience in data analysis, data engineering, and AI/ML engineering roles.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Summary for the Recruiter:\n",
            "The candidate is skilled in Python, SQL, and AWS, with experience in data analysis, data engineering, and AI/ML engineering roles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install langchain langchain-core langchain-community langchain_openai huggingface-hub requests -q -U\n",
        "!pip install arxiv pymupdf faiss-cpu chromadb tenacity PyPDF2 -q\n",
        "\n",
        "# Set up environment variables\n",
        "import os\n",
        "import getpass\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "OPENAI_API_KEY = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.tools import BaseTool\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Get user input for the resume file path\n",
        "resume_file_path = input(\"Enter the path to your resume file: \")\n",
        "\n",
        "# Load the resume file (PDF)\n",
        "reader = PdfReader(resume_file_path)\n",
        "resume_content = \"\"\n",
        "for page in reader.pages:\n",
        "    resume_content += page.extract_text()\n",
        "\n",
        "# Split the resume into chunks\n",
        "text_splitter = CharacterTextSplitter(separator='\\n---\\n', chunk_size=1000, chunk_overlap=0)\n",
        "resume_docs = text_splitter.split_documents([Document(page_content=resume_content)])\n",
        "\n",
        "# Create vector database and store the resume\n",
        "embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-ada-002\")\n",
        "db = Chroma.from_documents(resume_docs, embedding_model, persist_directory='./chroma_db')\n",
        "\n",
        "# Initialize the language model\n",
        "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=150)\n",
        "\n",
        "# Initialize the conversation memory\n",
        "chat_memory = ConversationBufferMemory(ai_prefix=\"AI Assistant\")\n",
        "\n",
        "# Define the conversation template\n",
        "template = \"\"\"\n",
        "You're an AI assistant and your task is to gather additional details from a candidate after they upload their resume.\n",
        "\n",
        "At the beginning, shortly describe the purpose of this conversation.\n",
        "\n",
        "You should gather answers for the following questions:\n",
        "\n",
        "- What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
        "- Can you provide an example of a project or accomplishment that demonstrates your qualifications?\n",
        "- What are your career goals and how do you see this position aligning with those goals?\n",
        "\n",
        "Don't answer the question you are asking.\n",
        "\n",
        "Be patient and encouraging if the candidate doesn't know how to answer some questions, and help guide them.\n",
        "\n",
        "Ask one question at a time and wait for the candidate's response before asking the next question.\n",
        "\n",
        "Once you have gathered all the details, thank the candidate for their responses, summarize the relevant information that will help the recruiter better understand their qualifications, and put ''\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "AI assistant:\n",
        "\"\"\"\n",
        "\n",
        "# Create the conversation prompt\n",
        "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
        "conversation = ConversationChain(\n",
        "    prompt=prompt,\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        "    memory=chat_memory\n",
        ")\n",
        "\n",
        "# Start the conversation\n",
        "print(\"AI Assistant: Great! Thank you for uploading your resume. The purpose of this conversation is to gather additional details to better understand your qualifications for the position you're applying for.\")\n",
        "print(\"AI Assistant: What specific skills or experiences do you have that are relevant to the position you're applying for?\")\n",
        "\n",
        "candidate_details = \"\"\n",
        "questions_asked = 0\n",
        "\n",
        "while questions_asked < 3:\n",
        "    user_input = input(\"Candidate: \")\n",
        "    candidate_details += f\"Candidate: {user_input}\\n\"\n",
        "\n",
        "    ai_response = conversation.predict(input=user_input)\n",
        "    print(f\"AI Assistant: {ai_response}\")\n",
        "\n",
        "    if '' in ai_response:\n",
        "        candidate_details += f\"AI Assistant: {ai_response.replace('', '')}\\n\"\n",
        "        questions_asked += 1\n",
        "\n",
        "        if questions_asked == 1:\n",
        "            print(\"AI Assistant: Can you provide an example of a project or accomplishment that demonstrates your qualifications?\")\n",
        "        elif questions_asked == 2:\n",
        "            print(\"AI Assistant: What are your career goals and how do you see this position aligning with those goals?\")\n",
        "\n",
        "# Initialize the RAG tool\n",
        "rag_tool = Tool(\n",
        "    name=\"RAG System\",\n",
        "    func=lambda q: db.similarity_search(q, k=3),\n",
        "    description=\"Useful for retrieving relevant information from the candidate's resume.\"\n",
        ")\n",
        "\n",
        "# Generate the summary using the agent with retry logic\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def generate_summary(query):\n",
        "    agent = initialize_agent([rag_tool], llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "    return agent.run(f\"Use the resume and additional details provided by the candidate to generate a summary for the recruiter: {query}\")\n",
        "\n",
        "try:\n",
        "    summary = generate_summary(candidate_details)\n",
        "except Exception as e:\n",
        "    print(f\"Error generating summary: {str(e)}\")\n",
        "    summary = \"I apologize, I encountered an error while generating the summary. I tried using the available information from the resume and additional details provided by the candidate, but I still don't have enough relevant information to provide a satisfactory summary for the recruiter. I would recommend gathering more specific details from the candidate related to their qualifications and experience.\"\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary for the Recruiter:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX5O059R0AvA",
        "outputId": "40db3846-5cd6-42ad-ed38-2f22006d3459"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API Key:··········\n",
            "Enter the path to your resume file: /content/Anurag Lahon Resume 2024.pdf\n",
            "AI Assistant: Great! Thank you for uploading your resume. The purpose of this conversation is to gather additional details to better understand your qualifications for the position you're applying for.\n",
            "AI Assistant: What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
            "Candidate: SQL, Python, AWS\n",
            "AI Assistant: Hello! The purpose of this conversation is to gather additional details from you after you have uploaded your resume. I will be asking you a few questions to better understand your skills and experiences relevant to the position you're applying for, as well as your career goals.\n",
            "\n",
            "What specific skills or experiences do you have that are relevant to the position you're applying for?\n",
            "AI Assistant: Can you provide an example of a project or accomplishment that demonstrates your qualifications?\n",
            "Candidate: Built an ETL pipeline to move from on premise to cloud using AWS\n",
            "AI Assistant: That's great to hear! Can you provide an example of a project or accomplishment that demonstrates your qualifications, such as building an ETL pipeline to move from on premise to cloud using AWS?\n",
            "AI Assistant: What are your career goals and how do you see this position aligning with those goals?\n",
            "Candidate: I wanted to work in the data field\n",
            "AI Assistant: What are your career goals and how do you see this position aligning with those goals?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI should focus on extracting relevant information about the candidate's experience with SQL, Python, and AWS.\n",
            "Action: RAG System\n",
            "Action Input: SQL, Python, AWS\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\"), Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\")]\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI have gathered relevant information about the candidate's experience with SQL, Python, and AWS from their resume.\n",
            "Action: RAG System\n",
            "Action Input: SQL, Python, AWS\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\"), Document(page_content=\"ANURAG LAHON (720)341-5435| Newark, Delaware| anurag.lahon@ucdenver.edu | LinkedIn | GitHub | Portfolio TECHNICAL SKILLS Database and Vector Database: PostgreSQL, MySQL, Cassandra, Pinecone,ChromaDB Data Visualization: Tableau, PowerBI, Excel, Plotly Tools: Jupyter, Git,AWS, SAS, Alteryx, Jira, Programming Languages: Python, R, SQL, JavaScript, HTML, CSS Big data Ecosystem: Hadoop, Hive, PySpark, HBase, Sqoop Libraries and Frameworks: PyTorch, TensorFlow, Numpy, Pandas, Langchain, LlamaIndex Deployment Platforms:                                         AWS Bedrock, AWS (EC2, Lambda),Hugging Face Spaces        AI/ML Techniques:                                                Fine-tuning with custom data, vector embedding, NLP,MLOPS        Generative AI Technologies:                                 Open-source and paid LLM models (Llama2, Mistral,OpenAI,Google Gemini Pro)  EDUCATION  University of Colorado, Denver Jan 2020 – Dec 2021 Master of Science in Business Analytics GPA: 3.9 Relevant Courses: Statistics, Computing for Business Analytics, Predictive Analytics, Project Management,Data Visualization, Prescriptive Analytics with optimization, Network Modeling, Time Series Forecasting, Web Analytics, Supply Chain Analytics Kalinga Institute of Industrial Technology, Bhubaneswar, India Aug 2013 – May 2017 Bachelor of Technology in Engineering EXPERIENCE   Data Analyst at Advithri Technologies LLC (Contract), Delaware                                                                       Oct 2023 - Feb 2024 •Enhanced data model accuracy and streamlined decision processes contributing to strategic business improvements. •Applied predictive analytics and ML algorithms for trend forecasting, achieving a 20% uplift in accuracy and significantly impacting strategic decision-making. •Leveraged Snowflake's cloud data platform to overhaul business intelligence processes, employing SQL, Python, and Power BI for robust data analysis and visualization, leading to actionable insights and enhanced decision-making. Manager, Data Engineering at CHEP USA, Delaware Jan 2023 – July 2023 •Developed software scripts to ETL data from 30 sources, including relational databases, spreadsheets, and flat files, for supporting B2B pricing software systems. Implemented Generative AI models for data analysis and optimization. •Automated business data problems, resulting in a 25% increase in operational efficiency using agile SDLC to support pricing and value-capture activities for optimizing profitability at strategic and tactical levels. •Enabled 15% surge in strategic insights through advanced data science driven cost analysis including GAI models for customers. •Directed successful completion of UAT by managing over 50 Jira stories and issues resulting in timely completion of the project. Data Analyst at JP Morgan Chase, Delaware Apr 2022 – Oct 2022 •Extracted, transformed, analyzed, and visualized financial market data from 6 sources using Tableau, SQL and Alteryx. AWS AI/ML Engineer at Global Technology Solutions LLC (GTS), Denver Jan 2022 – Mar 2022 •Built products for contact center using AWS services (Connect, Transcribe, Sagemaker,lambda,IAM) which reduced time by 40%.Led a technical team in applying ML models and GAI models for real-time data analysis and insights. Graduate Teaching Assistant at CU Denver Business School, Denver Aug 2020 – Dec 2021 •Evaluated assignments, exams, cleared concepts of 40 students, and reviewed the professor’s book. Engineer at M.P. AGARWALLA, India Jan 2018 – Aug 2019 •Examined the work, lead a group of 3 and communicated as a team. Machine Learning Teaching Assistant at Coding Ninjas, India May 2018 – Sep 2018 •Conducted teaching and doubt solving sessions for debugging codes and helping 100+ students to obtain a good understanding and grades assignments and projects. Achieved good 4.4 overallratings. PROJECTS   Q & A System Blog generation(Python, llam2-7B, PyTorch, streamlit, Docker)                                                                 Sep 2023 •Developed an end-to-end Question Answering system prototype utilizing Large Language Models and the Retrieval Augmented Generation(RAG) technique for natural language response compilation •Built data pipeline for ingesting proprietary knowledge base into vector database and implemented semantic search algorithms to retrieve answers relevant to natural language question •Formulated design strategy and considerations for transitioning prototype system into a scalable production environment •Gained extensive hands-on experience spanning data preprocessing, ingestion, semantic search, and answer compilation for building conversational AI agents over private data PDF Query and Celebrity Search Application (Python, OpenAI, LangChain, HuggingFace, streamlit) Jun 2023 •Enabled faster and more accurate information retrieval efficiently, saving time and enhance productivity. •Streamlined User Experience using Streamlit offers a highly interactive and user-friendly interface. •Advanced searched capabilities such as semantic similarity, keyword matching have enhanced precision. Credit Card Invitation (R, Python,Sagemak) Sep 2020 •Recommended the most likely customers to accept an invitation, keeping in mind the company’s budget. Used oversampling methods such as SMOTE for imbalanced classification while data preparation. Formula One Data Visualizing(Power BI,Tableau,Power Point) Aug 2020 •Cleaned,ETL,Joined, and Performed EDA of 12 files and utilize libraries for visualization and analysis. •Visualized how the Teams and drivers fared from 1950-2020 with Power BI and Tableau to create interactive analytical dashboards and reports that depict critical KPIs. ML Pipeline for Short Term Rental Prices in NYC (MLflow, Python, Weights & Biases) Jul 2020 •Created a clean, organized, reproducible, end-to-end machine learning pipeline from scratch using MLflow. •Tracked experiments, code and results. Selected the best-performing model for production. Sentiment Analysis (Python, AWS (Sagemaker, S3, Lambda Function, AWS Gateway),Glue) Mar 2018 •Assessed model performance of Naive Bayes, KNN, XGBoost, and SVC with the best accuracy of 88%. •Deployed a web app that collects a user's data, sends, and expects a positive (1) or negative (0) sentiment in return. AWARDS & CERTIFICATIONS •AWS SME (Subject Matter Expert) for AWS certification in the AI/ML space  Feb 2024 •Databricks Large Language Models: Application through Production Jun 2023 •Amazon Web Services Certified Machine Learning - Specialty, AWS Certified Cloud Practitioner. Oct 2021 •Business Graduate Merit Scholarship, Outstanding Graduate candidate at CU DenverBusiness School. Dec 2020\")]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI have gathered all the necessary information about the candidate's skills and experiences with SQL, Python, and AWS.\n",
            "Final Answer: The candidate has experience with SQL, Python, and AWS, with specific projects involving ETL pipelines, data analysis, and cloud services.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Summary for the Recruiter:\n",
            "The candidate has experience with SQL, Python, and AWS, with specific projects involving ETL pipelines, data analysis, and cloud services.\n"
          ]
        }
      ]
    }
  ]
}